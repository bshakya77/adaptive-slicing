{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTR3xEmfrJMy",
    "outputId": "24d90f2f-7690-43d0-ebfe-bad042d624b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ultralytics in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (8.3.96)\n",
      "Requirement already satisfied: gradio in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (4.44.1)\n",
      "Requirement already satisfied: matplotlib in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (3.8.2)\n",
      "Requirement already satisfied: pillow in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (10.2.0)\n",
      "Requirement already satisfied: numpy in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from ultralytics) (2.1.2+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from ultralytics) (0.16.2+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from ultralytics) (2.2.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (4.8.0)\n",
      "Requirement already satisfied: fastapi<1.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from gradio) (0.20.3)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from gradio) (6.1.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: packaging in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pydantic>=2.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from gradio) (2.5.3)\n",
      "Requirement already satisfied: pydub in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (0.11.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (0.15.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (2.4.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio) (0.34.2)\n",
      "Requirement already satisfied: fsspec in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from gradio-client==1.3.0->gradio) (2023.10.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from fastapi<1.0->gradio) (0.46.2)\n",
      "Requirement already satisfied: certifi in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio) (3.9.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
      "Requirement already satisfied: six>=1.5 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: sympy in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: networkx in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mmfs1/cm/shared/apps_local/python/shared_envs/torch11.8/lib/python3.9/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /mmfs1/home/dsu.local/bshakya/.local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Install Required Libraries\n",
    "!pip install ultralytics gradio matplotlib pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KE9XoNJLtyf3",
    "outputId": "61ffab04-926d-49a6-8864-7bd89ff9b4ae"
   },
   "outputs": [],
   "source": [
    "# Install Required Libraries (uncomment if needed)\n",
    "# !pip install ultralytics gradio matplotlib pillow torch torchvision tqdm pandas\n",
    "\n",
    "import os\n",
    "from ultralytics import YOLO, YOLOWorld, RTDETR\n",
    "from PIL import Image, ImageDraw\n",
    "import gradio as gr\n",
    "import torch\n",
    "from torchvision.ops import nms\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Model Download or Load Function\n",
    "def load_model(model_name):\n",
    "    \"\"\"\n",
    "    Automatically download and load the selected model from ultralytics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if model_name in [\"yolo11n\", \"yolov10n\", \"yolov9c\", \"yolov8n\", \"yolov5nu\", \"yolov6-n\"]:\n",
    "            model = YOLO(model_name)\n",
    "        elif model_name == \"rtdetr-l\":\n",
    "            model = RTDETR(model_name)\n",
    "        elif model_name == \"yolov8s-worldv2\":\n",
    "            model = YOLOWorld(model_name)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading model {model_name}: {e}\")\n",
    "\n",
    "# Apply Non-Maximum Suppression (NMS)\n",
    "def apply_nms(detections, iou_threshold=0.5):\n",
    "    boxes, scores, labels = [], [], []\n",
    "    for det in detections:\n",
    "        boxes.append(det['box'])\n",
    "        scores.append(det['confidence'])\n",
    "        labels.append(det['class_id'])\n",
    "    boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "    scores = torch.tensor(scores, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    keep_indices = []\n",
    "    unique_labels = labels.unique()\n",
    "    for label in unique_labels:\n",
    "        idxs = (labels == label).nonzero(as_tuple=False).squeeze(1)\n",
    "        class_boxes = boxes[idxs]\n",
    "        class_scores = scores[idxs]\n",
    "        keep = nms(class_boxes, class_scores, iou_threshold)\n",
    "        keep_indices.extend(idxs[keep].tolist())\n",
    "\n",
    "    return [detections[i] for i in keep_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VaiZsgmluCT8"
   },
   "outputs": [],
   "source": [
    "# Full-Image Detection Function\n",
    "def detect_full_image(image, model, confidence_threshold=0.25):\n",
    "    results = model.predict(image, conf=confidence_threshold)[0]\n",
    "    detections = []\n",
    "    for box in results.boxes:\n",
    "        xmin, ymin, xmax, ymax = map(int, box.xyxy[0].tolist())\n",
    "        class_id = int(box.cls[0].item())\n",
    "        confidence = box.conf[0].item()\n",
    "        detections.append({\n",
    "            \"box\": [xmin, ymin, xmax, ymax],\n",
    "            \"class_id\": class_id,\n",
    "            \"class_name\": model.names[class_id],\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "    return apply_nms(detections)\n",
    "\n",
    "# Guided Object Inference Slicing Function\n",
    "def guided_object_inference_slicing(image, model, CoarseToFine_Slcing=516, overlap=0.2, confidence_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Divides the image into overlapping patches using the parameter 'CoarseToFine_Slcing'\n",
    "    and applies the model to each patch.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    detections = []\n",
    "    step = int(CoarseToFine_Slcing * (1 - overlap))  # Compute step size based on overlap\n",
    "\n",
    "    for y in range(0, height, step):\n",
    "        for x in range(0, width, step):\n",
    "            box = (x, y, min(x + CoarseToFine_Slcing, width), min(y + CoarseToFine_Slcing, height))\n",
    "            crop = image.crop(box)\n",
    "            results = model.predict(crop, conf=confidence_threshold)[0]\n",
    "            for box_obj in results.boxes:\n",
    "                xmin, ymin, xmax, ymax = map(int, box_obj.xyxy[0].tolist())\n",
    "                # Adjust coordinates relative to the original image\n",
    "                xmin += x\n",
    "                xmax += x\n",
    "                ymin += y\n",
    "                ymax += y\n",
    "                detections.append({\n",
    "                    \"box\": [xmin, ymin, xmax, ymax],\n",
    "                    \"class_id\": int(box_obj.cls[0].item()),\n",
    "                    \"class_name\": model.names[int(box_obj.cls[0].item())],\n",
    "                    \"confidence\": box_obj.conf[0].item()\n",
    "                })\n",
    "    return apply_nms(detections)\n",
    "\n",
    "# Draw Detections\n",
    "def draw_detections(image, detections):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for det in detections:\n",
    "        xmin, ymin, xmax, ymax = det[\"box\"]\n",
    "        class_name = det[\"class_name\"]\n",
    "        confidence = det[\"confidence\"]\n",
    "        label = f\"{class_name} {confidence:.2f}\"\n",
    "        draw.rectangle([xmin, ymin, xmax, ymax], outline=\"red\", width=2)\n",
    "        draw.text((xmin, ymin), label, fill=\"yellow\")\n",
    "    return image\n",
    "\n",
    "# Process Images with Progress Bar\n",
    "def process_images(image_paths, model_name, confidence_threshold):\n",
    "    model = load_model(model_name)\n",
    "    original_images, full_images, gois_images, metrics = [], [], [], []\n",
    "    image_names = []\n",
    "\n",
    "    for image_path in tqdm(image_paths, desc=\"Processing Images\"):\n",
    "        image_name = os.path.basename(image_path)\n",
    "        image_names.append(image_name)\n",
    "        original_image = Image.open(image_path).convert(\"RGB\")\n",
    "        original_images.append(original_image)\n",
    "\n",
    "        # Full detection\n",
    "        full_detections = detect_full_image(original_image.copy(), model, confidence_threshold)\n",
    "        full_image_result = draw_detections(original_image.copy(), full_detections)\n",
    "        full_images.append(full_image_result)\n",
    "\n",
    "        # Guided Object Inference Slicing detection\n",
    "        gois_detections = guided_object_inference_slicing(original_image.copy(), model, confidence_threshold=confidence_threshold)\n",
    "        gois_image_result = draw_detections(original_image.copy(), gois_detections)\n",
    "        gois_images.append(gois_image_result)\n",
    "\n",
    "        # Metrics calculation\n",
    "        metrics.append({\n",
    "            \"Image Name\": image_name,\n",
    "            \"Total Detections (Full)\": len(full_detections),\n",
    "            \"Total Detections (Sliced)\": len(gois_detections),\n",
    "        })\n",
    "\n",
    "    return original_images, full_images, gois_images, metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FUy3IlIZI4F7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 0/23 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov8n\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m confidence_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m\n\u001b[0;32m----> 4\u001b[0m original_images, full_images, gois_images, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidence_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 68\u001b[0m, in \u001b[0;36mprocess_images\u001b[0;34m(image_paths, model_name, confidence_threshold)\u001b[0m\n\u001b[1;32m     66\u001b[0m image_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(image_path)\n\u001b[1;32m     67\u001b[0m image_names\u001b[38;5;241m.\u001b[39mappend(image_name)\n\u001b[0;32m---> 68\u001b[0m original_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m original_images\u001b[38;5;241m.\u001b[39mappend(original_image)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Full detection\u001b[39;00m\n",
      "File \u001b[0;32m/mmfs1/cm/shared/apps_local/python/3.11/envs/torch11.8/lib/python3.9/site-packages/PIL/Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '.'"
     ]
    }
   ],
   "source": [
    "image_paths = './single_test/images_v1'\n",
    "model_name = 'yolov8n'\n",
    "confidence_threshold = 0.3\n",
    "original_images, full_images, gois_images, metrics = process_images(image_paths, model_name, confidence_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "5tEph0FiuGot",
    "outputId": "5834c193-0b5d-400d-9005-a497ad853fd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://0aae61b92eadcb528d.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0aae61b92eadcb528d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio Interface Pipeline\n",
    "def gradio_pipeline(image_paths, model_name, confidence_threshold):\n",
    "    original_images, full_images, gois_images, metrics = process_images(image_paths, model_name, confidence_threshold)\n",
    "    print(gois_images)\n",
    "    metrics_table = pd.DataFrame(metrics).to_html(index=False, border=1, justify=\"center\")\n",
    "    return metrics_table, original_images, full_images, gois_images\n",
    "\n",
    "# Gradio Interface Setup\n",
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown(\"# Dynamic Model Selection with GOIS and YOLO Framework\")\n",
    "    with gr.Row():\n",
    "        model_dropdown = gr.Dropdown(\n",
    "            label=\"Select Model\",\n",
    "            choices=[\"yolo11n\", \"yolov10n\", \"yolov9c\", \"yolov8n\", \"yolov5nu\", \"rtdetr-l\", \"yolov8s-worldv2\"],\n",
    "        )\n",
    "        confidence_slider = gr.Slider(0.1, 1.0, value=0.25, label=\"Confidence Threshold\")\n",
    "    with gr.Row():\n",
    "        image_input = gr.File(label=\"Upload Images\", file_types=[\"image\"], type=\"filepath\", file_count=\"multiple\")\n",
    "    run_button = gr.Button(\"Run Detection\")\n",
    "\n",
    "    with gr.Row():\n",
    "        metrics_output = gr.HTML(label=\"Detection Metrics Table\")\n",
    "        original_gallery = gr.Gallery(label=\"Original Images\")\n",
    "        full_gallery = gr.Gallery(label=\"Full Image Detections\")\n",
    "        gois_gallery = gr.Gallery(label=\"GOIS-Sliced Image Detections\")\n",
    "\n",
    "    run_button.click(\n",
    "        fn=gradio_pipeline,\n",
    "        inputs=[image_input, model_dropdown, confidence_slider],\n",
    "        outputs=[metrics_output, original_gallery, full_gallery, gois_gallery]\n",
    "    )\n",
    "\n",
    "interface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:torch11.8]",
   "language": "python",
   "name": "conda-env-torch11.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
