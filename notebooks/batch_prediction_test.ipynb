{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654c28af-2faa-4115-bbfd-fe4342a52136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required functions and classes\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.utils.cv import read_image, read_image_as_pil\n",
    "from sahi.utils.file import Path, increment_path, list_files, save_json, save_pickle, download_from_url\n",
    "from sahi.predict import get_prediction, get_sliced_prediction, predict, agg_prediction, get_prediction_batched, get_sliced_prediction_batched, get_batch_predict\n",
    "#from sahi.predict_batch import get_prediction, get_sliced_prediction, predict, agg_prediction\n",
    "from sahi.prediction import visualize_object_predictions\n",
    "from IPython.display import Image\n",
    "from numpy import asarray\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca8677e-f20e-4188-99a5-9bafb6d72799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download YOLOv8-S model to 'models/yolov8s.pt'\n",
    "yolov11_model_path = 'models/yolo11/last.pt'\n",
    "yolov8_model_path = 'models/yolov8/last.pt'\n",
    "#download_yolov8s_model(destination_path=yolov8_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cefc8c1f-4109-466a-a128-835ae79dd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type='ultralytics',\n",
    "    model_path=yolov8_model_path,\n",
    "    confidence_threshold=0.3,\n",
    "    device=\"cuda:0\", # or 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21980e5b-70d3-49a6-85dc-f18d2d5d60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def get_slice_parameters(object_density):\n",
    "    \n",
    "    #image_path = \"test_data/0000006_06773_d_0000018.jpg\"\n",
    "    #image = Image.open(image_path).convert(\"RGB\")\n",
    "    #image_width, image_height  = image.size\n",
    "    #slice_width = image_width\n",
    "    #slice_height = image_height\n",
    "    #overlap_width_ratio = 0.0\n",
    "    #overlap_height_ratio = 0.0\n",
    "\n",
    "    if object_density >= 50:\n",
    "        slice_width = 512\n",
    "        slice_height = 512\n",
    "        overlap_width_ratio = 0.5\n",
    "        overlap_height_ratio = 0.5\n",
    "    elif 25 <= object_density < 50:\n",
    "        slice_width = 512\n",
    "        slice_height = 512\n",
    "        overlap_width_ratio = 0.25\n",
    "        overlap_height_ratio = 0.25\n",
    "    elif 10 <= object_density < 25:\n",
    "        slice_width = 512\n",
    "        slice_height = 512\n",
    "        overlap_width_ratio = 0.15\n",
    "        overlap_height_ratio = 0.15\n",
    "    else:\n",
    "        slice_width = 1024\n",
    "        slice_height = 1024\n",
    "        overlap_width_ratio = 0.15\n",
    "        overlap_height_ratio = 0.15\n",
    "\n",
    "    return slice_width, slice_height, overlap_width_ratio, overlap_height_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c3b0d58-d480-4677-87ad-99410de04588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d59372b-4225-43a8-a91b-2dd5f63fd759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Image Path:  single_test/images/0000078_03171_d_0000009.jpg\n",
      "File Name 0000078_03171_d_0000009\n",
      "Prediction performed in 0.013099908828735352 seconds.\n",
      "Initial Prediction time is: 23.55 ms\n",
      "Object Density: 55\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'single_test/images'\n",
    "for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            #image_as_pil = read_image_as_pil(image_path)\n",
    "            filename_without_ext = Path(filename).stem\n",
    "            \n",
    "            print(\"*****************************************\")\n",
    "            print(\"Image Path: \", image_path)\n",
    "            print(\"File Name\", filename_without_ext)\n",
    "\n",
    "            #img_id = get_image_id(data, filename_without_ext)\n",
    "            #image_ids.append(image_id)\n",
    "\n",
    "            # Get predictions from your detection model\n",
    "            time_start = time.time()\n",
    "            prediction = get_prediction(image_path, detection_model, verbose=1) #changes\n",
    "            time_end = time.time() - time_start\n",
    "            print(\"Initial Prediction time is: {:.2f} ms\".format(time_end * 1000))\n",
    "            \n",
    "            object_density = len(prediction.object_prediction_list)\n",
    "            print(\"Object Density:\", object_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea7fdf49-2ff0-4d14-87c7-bc6d85109acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Image Path:  single_test/images/0000078_03171_d_0000009.jpg\n",
      "File Name 0000078_03171_d_0000009\n",
      "Image Type 1 \n",
      "Length of SHIFT AMOUNT:  [[0, 0]]\n",
      "SHIFT AMOUNT:  [[0, 0]]\n",
      "FULL SHAPE:  [None]\n",
      "Prediction performed in 0.013222932815551758 seconds.\n",
      "Initial Prediction time is: 23.80 ms\n",
      "Object Density: 55\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'single_test/images'\n",
    "for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            #image_as_pil = read_image_as_pil(image_path)\n",
    "            filename_without_ext = Path(filename).stem\n",
    "            \n",
    "            print(\"*****************************************\")\n",
    "            print(\"Image Path: \", image_path)\n",
    "            print(\"File Name\", filename_without_ext)\n",
    "\n",
    "            #img_id = get_image_id(data, filename_without_ext)\n",
    "            #image_ids.append(image_id)\n",
    "\n",
    "            # Get predictions from your detection model\n",
    "            time_start = time.time()\n",
    "            prediction = get_prediction_batched(image_path, detection_model, verbose=1) #changes\n",
    "            time_end = time.time() - time_start\n",
    "            print(\"Initial Prediction time is: {:.2f} ms\".format(time_end * 1000))\n",
    "            \n",
    "            object_density = len(prediction.object_prediction_list)\n",
    "            print(\"Object Density:\", object_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96848c74-5c6e-48a7-8e17-d199dc09ecfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Image Path:  single_test/images_bk/0000006_06773_d_0000018.jpg\n",
      "File Name 0000006_06773_d_0000018\n",
      "Prediction performed in 0.013345479965209961 seconds.\n",
      "Initial Prediction time is: 24.49 ms\n",
      "Object Density: 37\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'single_test/images_bk'\n",
    "for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            #image_as_pil = read_image_as_pil(image_path)\n",
    "            filename_without_ext = Path(filename).stem\n",
    "            \n",
    "            print(\"*****************************************\")\n",
    "            print(\"Image Path: \", image_path)\n",
    "            print(\"File Name\", filename_without_ext)\n",
    "\n",
    "            #img_id = get_image_id(data, filename_without_ext)\n",
    "            #image_ids.append(image_id)\n",
    "\n",
    "            # Get predictions from your detection model\n",
    "            time_start = time.perf_counter()\n",
    "            prediction = get_prediction(image_path, detection_model, shift_amount = [250, 250],full_shape = [image_height, image_width], verbose=1) #changes\n",
    "            time_end = time.perf_counter() - time_start\n",
    "            print(\"Initial Prediction time is: {:.2f} ms\".format(time_end * 1000))\n",
    "            \n",
    "            object_density = len(prediction.object_prediction_list)\n",
    "            print(\"Object Density:\", object_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd8622fb-20a2-4924-a94e-da07c33635c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "image_width, image_height 1360 765\n",
      "Image Path:  single_test/images_bk/0000006_06773_d_0000018.jpg\n",
      "File Name 0000006_06773_d_0000018\n",
      "Image Type 1 \n",
      "Length of SHIFT AMOUNT:  [250, 250]\n",
      "SHIFT AMOUNT:  [250, 250]\n",
      "FULL SHAPE:  [[765, 1360], [765, 1360]]\n",
      "Prediction performed in 0.012885332107543945 seconds.\n",
      "Initial Prediction time is: 23.74 ms\n",
      "Object Density: 37\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'single_test/images_bk'\n",
    "for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image_as_pil = read_image_as_pil(image_path)\n",
    "            filename_without_ext = Path(filename).stem\n",
    "            image_width, image_height = image_as_pil.size\n",
    "            print(\"*****************************************\")\n",
    "            print(\"image_width, image_height\", image_width, image_height)\n",
    "            print(\"Image Path: \", image_path)\n",
    "            print(\"File Name\", filename_without_ext)\n",
    "\n",
    "            #img_id = get_image_id(data, filename_without_ext)\n",
    "            #image_ids.append(image_id)\n",
    "\n",
    "            # Get predictions from your detection model\n",
    "            time_start = time.perf_counter()\n",
    "            prediction = get_prediction_batched(image_path, detection_model,  shift_amount_list = [250, 250], full_shape = [image_height, image_width], verbose=1) #changes\n",
    "            time_end = time.perf_counter() - time_start\n",
    "            print(\"Initial Prediction time is: {:.2f} ms\".format(time_end * 1000))\n",
    "            \n",
    "            object_density = len(prediction.object_prediction_list)\n",
    "            print(\"Object Density:\", object_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d491eb7-4839-4356-ba86-f9e826ccd0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.91 ðŸš€ Python-3.9.18 torch-2.1.2+cu118 CUDA:0 (NVIDIA A100 80GB PCIe, 81229MiB)\n",
      "Setup complete âœ… (48 CPUs, 503.3 GB RAM, 26.7/430.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "280c8409-416e-4ebc-95f2-5fd718b2ceb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/single_test/images/0000078_03171_d_0000009.jpg: 384x640 9 pedestrians, 1 car, 51 trucks, 1 tricycle, 4.7ms\n",
      "Speed: 1.3ms preprocess, 4.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "YOLO Prediction time is: 76.68 ms\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "#model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
    "model = YOLO('models/yolov8/last.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "time_start = time.perf_counter()\n",
    "results = model.predict('single_test/images/0000078_03171_d_0000009.jpg')\n",
    "time_end = time.perf_counter() - time_start\n",
    "print(\"YOLO Prediction time is: {:.2f} ms\".format(time_end * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c15f7a7-c238-4d60-9425-7d5522aa91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bounding boxes and classes\n",
    "bounding_boxes = results[0].boxes  # [x, y, width, height] for each detected object\n",
    "object_count = len(bounding_boxes)  # Number of detected objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b604620-a480-40c9-a23e-2464c88cbc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f237714-7a89-4734-8278-3c4cf4ba9ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000011_04202_d_0000007.jpg: 640x640 7 pedestrians, 3 peoples, 1 bicycle, 2 cars, 6 trucks, 2 tricycles, 3 awning-tricycles, 2 buss, 1 motor, 60.5ms\n",
      "image 2/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000054_00786_d_0000001.jpg: 640x640 80 pedestrians, 1 car, 3 motors, 60.5ms\n",
      "image 3/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000074_07850_d_0000015.jpg: 640x640 57 pedestrians, 2 peoples, 3 bicycles, 4 cars, 1 motor, 60.5ms\n",
      "image 4/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000074_08202_d_0000016.jpg: 640x640 70 pedestrians, 1 people, 1 tricycle, 60.5ms\n",
      "image 5/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000078_01314_d_0000004.jpg: 640x640 (no detections), 1.1ms\n",
      "image 6/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000078_06777_d_0000020.jpg: 640x640 1 car, 2 trucks, 1.1ms\n",
      "image 7/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000087_00299_d_0000002.jpg: 640x640 84 pedestrians, 2 peoples, 1.1ms\n",
      "image 8/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000087_01580_d_0000005.jpg: 640x640 51 pedestrians, 6 peoples, 1.1ms\n",
      "image 9/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000186_01387_d_0000188.jpg: 384x640 4 peoples, 13 cars, 4 vans, 1 awning-tricycle, 4 motors, 18.3ms\n",
      "image 10/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000187_00444_d_0000190.jpg: 384x640 21 cars, 4 vans, 1 truck, 1 awning-tricycle, 10 motors, 18.3ms\n",
      "image 11/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000189_00297_d_0000198.jpg: 384x640 4 peoples, 19 cars, 2 trucks, 2 awning-tricycles, 5 motors, 18.3ms\n",
      "image 12/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000192_00522_d_0000213.jpg: 384x640 3 peoples, 19 cars, 1 van, 1 tricycle, 1 awning-tricycle, 6 motors, 18.3ms\n",
      "image 13/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000207_00300_d_0000004.jpg: 640x640 2 pedestrians, 26 cars, 2 tricycles, 24.2ms\n",
      "image 14/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000207_00600_d_0000007.jpg: 640x640 1 pedestrian, 1 people, 35 cars, 2 vans, 2 trucks, 1 bus, 2 motors, 24.2ms\n",
      "image 15/15 /mmfs1/scratch/dsu.local/bshakya/scratch/bshakya/sahi/test_vis_data/images/0000259_00500_d_0000002.jpg: 640x640 5 pedestrians, 5 peoples, 15 cars, 3 vans, 13 motors, 24.2ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 0.5ms postprocess per image at shape (4, 3, 640, 640)\n",
      "YOLO Prediction time is: 500.33 ms\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "results = model.predict(source='test_vis_data/images', batch=4)\n",
    "time_end = time.time() - time_start\n",
    "print(\"YOLO Prediction time is: {:.2f} ms\".format(time_end * 1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch11.8]",
   "language": "python",
   "name": "conda-env-torch11.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
