{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826d8598-8f11-4e44-b49b-c5fd10ef2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required functions and classes\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.utils.cv import read_image, read_image_as_pil\n",
    "from sahi.utils.file import Path, increment_path, list_files, save_json, save_pickle, download_from_url\n",
    "from sahi.predict import get_prediction, get_sliced_prediction, predict, agg_prediction, get_prediction_batched, get_sliced_prediction_batched, predict \n",
    "from sahi.prediction import visualize_object_predictions\n",
    "from IPython.display import Image\n",
    "from numpy import asarray\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sahi.prediction import ObjectPrediction, PredictionResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77708be4-9518-4722-b8d0-d649a7d096bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download YOLOv8-S model to 'models/yolov8s.pt'\n",
    "yolov8_model_path = 'models/yolov8/last.pt'\n",
    "#download_yolov8s_model(destination_path=yolov8_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7968ac47-3f2f-4a22-addd-18b5019228cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type='yolov8',\n",
    "    model_path=yolov8_model_path,\n",
    "    confidence_threshold=0.3,\n",
    "    device=\"cuda:0\", # or 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6017672-087f-4165-bb0a-06fd3ffe3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "def get_slice_parameters(object_density, slice_size):\n",
    "    \n",
    "    #start_time = time.time()\n",
    "    #image_path = \"test_data/0000006_06773_d_0000018.jpg\"\n",
    "    #image = Image.open(image_path).convert(\"RGB\")\n",
    "    #image_width, image_height  = image.size\n",
    "    #print(\"Image Width:\", image_width)\n",
    "    #print(\"Image Height:\", image_height)\n",
    "    #min_dim = min(image_width, image_height)\n",
    "    #slice_size = min_dim // 4 if min_dim > 1600 else min_dim // 2\n",
    "    #print(f\"Dimension calculation time taken: {(time.time() - start_time)*1000:.2f} ms\")\n",
    "\n",
    "    \n",
    "    if object_density >= 50:\n",
    "        #slice_size = min_dim // 4\n",
    "        slice_width = slice_size\n",
    "        slice_height = slice_size\n",
    "        overlap_width_ratio = 0.5\n",
    "        overlap_height_ratio = 0.5\n",
    "    elif 25 <= object_density < 50:\n",
    "        #slice_size = min_dim // 2\n",
    "        slice_width = slice_size\n",
    "        slice_height = slice_size\n",
    "        overlap_width_ratio = 0.25\n",
    "        overlap_height_ratio = 0.25\n",
    "    elif 10 <= object_density < 25:\n",
    "        #slice_size = min_dim // 2\n",
    "        slice_width = slice_size\n",
    "        slice_height = slice_size\n",
    "        overlap_width_ratio = 0.15\n",
    "        overlap_height_ratio = 0.15\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    return slice_width, slice_height, overlap_width_ratio, overlap_height_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0e86f8-1a85-45e8-846b-020e5ffc16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get image details by image_id\n",
    "def get_image_id(coco_data, image_name):\n",
    "    for image in coco_data[\"images\"]:\n",
    "        file_name = Path(image['file_name']).stem\n",
    "        if file_name == image_name:\n",
    "            return image['id']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc46f088-80a5-40fa-bbcb-07f519a135ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export visualization\n",
    "def predict_sliced_images(input_folder, dataset_json_path, detection_model, slice_size):\n",
    "    \"\"\"\n",
    "    Processes all image files in input_folder:\n",
    "      - Runs predictions using get_prediction function and detection_model.\n",
    "      - Saves annotated images with bounding boxes in output_folder.\n",
    "      - Saves prediction details as JSON files in output_folder.\n",
    "    \n",
    "    Parameters:\n",
    "      input_folder (str): Path to the folder containing images.\n",
    "      detection_model: Your detection model used for prediction.\n",
    "      slice_size (int): Parameter for slice size used in get_slice_parameters.\n",
    "    \"\"\"\n",
    "    name = \"exp\"\n",
    "    save_dir = Path(increment_path(Path(\"sliced_predictions\") / name, exist_ok=False))\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    if dataset_json_path:\n",
    "        with open(dataset_json_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "    \n",
    "    # Visualization parameters\n",
    "    visual_bbox_gt_thickness = 3\n",
    "    visual_bbox_thickness = 2\n",
    "    visual_text_size = 0.5\n",
    "    visual_text_thickness = 1\n",
    "    visual_hide_labels = False\n",
    "    visual_hide_conf = False\n",
    "    visual_export_format = 'png'\n",
    "    \n",
    "    sliced_predictions = []\n",
    "    coco_json = []\n",
    "    \n",
    "    # Initialize a variable to accumulate total prediction time for all images.\n",
    "    total_prediction_time = 0.0\n",
    "    \n",
    "    # Loop over files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image_as_pil = read_image_as_pil(image_path)\n",
    "            filename_without_ext = Path(filename).stem\n",
    "            \n",
    "            print(\"*****************************************\")\n",
    "            print(\"File Name\", filename_without_ext)\n",
    "\n",
    "            img_id = get_image_id(data, filename_without_ext)\n",
    "            \n",
    "            # Get initial predictions from your detection model\n",
    "            time_start = time.time()\n",
    "            prediction = get_prediction(image_path, detection_model)\n",
    "            time_end = time.time() - time_start\n",
    "            print(\"Initial Prediction time is: {:.2f} ms\".format(time_end * 1000))\n",
    "            \n",
    "            # Add initial prediction time to the cumulative total.\n",
    "            iteration_time = time_end\n",
    "            \n",
    "            object_density = len(prediction.object_prediction_list)\n",
    "            print(\"Object Density:\", object_density)\n",
    "            \n",
    "            if object_density > 10:\n",
    "                slice_width, slice_height, overlap_width_ratio, overlap_height_ratio = get_slice_parameters(object_density, slice_size)\n",
    "    \n",
    "                print(\"********* Slice Parameters ***********\")\n",
    "                print(\"Slice Width: \", slice_width)\n",
    "                print(\"Slice Height: \", slice_height)\n",
    "                print(\"Overlap Width Ratio: \", overlap_width_ratio)\n",
    "                print(\"Overlap Height Ratio: \", overlap_height_ratio)\n",
    "\n",
    "                time_start_slice = time.time()\n",
    "                result_sahi = get_sliced_prediction(\n",
    "                    image_path,\n",
    "                    detection_model,\n",
    "                    slice_height=slice_height,\n",
    "                    slice_width=slice_width,\n",
    "                    overlap_height_ratio=overlap_height_ratio,\n",
    "                    overlap_width_ratio=overlap_width_ratio,\n",
    "                    postprocess_min_area=16,\n",
    "                    postprocess_type=\"TruncatedNMS\",\n",
    "                    verbose=2\n",
    "                )\n",
    "                time_end_slice = time.time() - time_start_slice\n",
    "                print(\"Sliced Prediction time is: {:.2f} ms\".format(time_end_slice * 1000))\n",
    "                \n",
    "                # Add sliced prediction time to the current iteration's total.\n",
    "                iteration_time += time_end_slice\n",
    "                \n",
    "                coco_prediction = result_sahi.to_coco_predictions(image_id=img_id)\n",
    "                for idx, predict in enumerate(coco_prediction):\n",
    "                    if coco_prediction[idx][\"bbox\"]:\n",
    "                        coco_json.append(predict)\n",
    "                    \n",
    "                sliced_predictions.append(result_sahi)\n",
    "                \n",
    "                visualize_object_predictions(\n",
    "                    np.ascontiguousarray(image_as_pil),\n",
    "                    object_prediction_list=result_sahi.object_prediction_list,\n",
    "                    rect_th=visual_bbox_thickness,\n",
    "                    text_size=visual_text_size,\n",
    "                    text_th=visual_text_thickness,\n",
    "                    hide_labels=visual_hide_labels,\n",
    "                    hide_conf=visual_hide_conf,\n",
    "                    output_dir=save_dir,\n",
    "                    file_name=filename_without_ext,\n",
    "                    export_format=visual_export_format,\n",
    "                )\n",
    "                \n",
    "            else:\n",
    "                print(\"Prediction time is: {:.2f} ms\".format(time_end * 1000))\n",
    "                \n",
    "                coco_prediction = prediction.to_coco_predictions(image_id=img_id)\n",
    "                for idx, predict in enumerate(coco_prediction):\n",
    "                    if coco_prediction[idx][\"bbox\"]:\n",
    "                        coco_json.append(predict)\n",
    "                    \n",
    "                sliced_predictions.append(prediction)\n",
    "                \n",
    "                visualize_object_predictions(\n",
    "                    np.ascontiguousarray(image_as_pil),\n",
    "                    object_prediction_list=prediction.object_prediction_list,\n",
    "                    rect_th=visual_bbox_thickness,\n",
    "                    text_size=visual_text_size,\n",
    "                    text_th=visual_text_thickness,\n",
    "                    hide_labels=visual_hide_labels,\n",
    "                    hide_conf=visual_hide_conf,\n",
    "                    output_dir=save_dir,\n",
    "                    file_name=filename_without_ext,\n",
    "                    export_format=visual_export_format,\n",
    "                )\n",
    "            \n",
    "            # Update the overall total prediction time\n",
    "            total_prediction_time += iteration_time\n",
    "                 \n",
    "    if dataset_json_path:\n",
    "        save_path = str(save_dir / \"result.json\")\n",
    "        save_json(coco_json, save_path)\n",
    "        print(f\"Prediction results are successfully exported to {save_dir}\")\n",
    "    \n",
    "    print(f\"Prediction Completed Successfully: {len(sliced_predictions)} images\")\n",
    "    print(\"Total Prediction time for all images is: {:.2f} ms\".format(total_prediction_time * 1000))\n",
    "    return sliced_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25fe36d-65b2-46a0-9015-19d58da8591a",
   "metadata": {},
   "source": [
    "#### **Usage**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd9e70-c704-44c2-ae65-7182721b697d",
   "metadata": {},
   "source": [
    "#### **Subset of 15 images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37416127-8b2b-43f7-a668-7cd838ef350a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "File Name 0000207_00300_d_0000004\n",
      "Initial Prediction time is: 15.51 ms\n",
      "Object Density: 25\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 213\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  213\n",
      "Final Bounding Box Count (Truncated NMS):  63\n",
      "Slicing performed in 0.0029900074005126953 seconds.\n",
      "Prediction performed in 0.21706771850585938 seconds.\n",
      "Sliced Prediction time is: 220.47 ms\n",
      "*****************************************\n",
      "File Name 0000074_07850_d_0000015\n",
      "Initial Prediction time is: 37.92 ms\n",
      "Object Density: 53\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 826\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  826\n",
      "Final Bounding Box Count (Truncated NMS):  154\n",
      "Slicing performed in 0.010547399520874023 seconds.\n",
      "Prediction performed in 1.4514787197113037 seconds.\n",
      "Sliced Prediction time is: 1459.88 ms\n",
      "*****************************************\n",
      "File Name 0000187_00444_d_0000190\n",
      "Initial Prediction time is: 15.28 ms\n",
      "Object Density: 32\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 196\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  196\n",
      "Final Bounding Box Count (Truncated NMS):  40\n",
      "Slicing performed in 0.0029304027557373047 seconds.\n",
      "Prediction performed in 0.175703763961792 seconds.\n",
      "Sliced Prediction time is: 178.18 ms\n",
      "*****************************************\n",
      "File Name 0000207_00600_d_0000007\n",
      "Initial Prediction time is: 15.10 ms\n",
      "Object Density: 40\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 343\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  343\n",
      "Final Bounding Box Count (Truncated NMS):  93\n",
      "Slicing performed in 0.003229379653930664 seconds.\n",
      "Prediction performed in 0.34474778175354004 seconds.\n",
      "Sliced Prediction time is: 347.40 ms\n",
      "*****************************************\n",
      "File Name 0000087_00299_d_0000002\n",
      "Initial Prediction time is: 14.31 ms\n",
      "Object Density: 67\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 382\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  382\n",
      "Final Bounding Box Count (Truncated NMS):  106\n",
      "Slicing performed in 0.0027837753295898438 seconds.\n",
      "Prediction performed in 0.4012296199798584 seconds.\n",
      "Sliced Prediction time is: 404.20 ms\n",
      "*****************************************\n",
      "File Name 0000259_00500_d_0000002\n",
      "Initial Prediction time is: 21.37 ms\n",
      "Object Density: 34\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "Sliced Boxes Count: 8\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 109\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  109\n",
      "Final Bounding Box Count (Truncated NMS):  44\n",
      "Slicing performed in 0.0053501129150390625 seconds.\n",
      "Prediction performed in 0.1916346549987793 seconds.\n",
      "Sliced Prediction time is: 195.84 ms\n",
      "*****************************************\n",
      "File Name 0000074_08202_d_0000016\n",
      "Initial Prediction time is: 38.90 ms\n",
      "Object Density: 50\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 672\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  672\n",
      "Final Bounding Box Count (Truncated NMS):  133\n",
      "Slicing performed in 0.010323047637939453 seconds.\n",
      "Prediction performed in 1.111893892288208 seconds.\n",
      "Sliced Prediction time is: 1120.45 ms\n",
      "*****************************************\n",
      "File Name 0000011_04202_d_0000007\n",
      "Initial Prediction time is: 23.29 ms\n",
      "Object Density: 22\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.15\n",
      "Overlap Height Ratio:  0.15\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 72\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  72\n",
      "Final Bounding Box Count (Truncated NMS):  30\n",
      "Slicing performed in 0.006154298782348633 seconds.\n",
      "Prediction performed in 0.14130139350891113 seconds.\n",
      "Sliced Prediction time is: 146.05 ms\n",
      "*****************************************\n",
      "File Name 0000189_00297_d_0000198\n",
      "Initial Prediction time is: 15.12 ms\n",
      "Object Density: 31\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 210\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  210\n",
      "Final Bounding Box Count (Truncated NMS):  44\n",
      "Slicing performed in 0.00287628173828125 seconds.\n",
      "Prediction performed in 0.1888728141784668 seconds.\n",
      "Sliced Prediction time is: 191.58 ms\n",
      "*****************************************\n",
      "File Name 0000186_01387_d_0000188\n",
      "Initial Prediction time is: 14.56 ms\n",
      "Object Density: 24\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.15\n",
      "Overlap Height Ratio:  0.15\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 173\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  173\n",
      "Final Bounding Box Count (Truncated NMS):  47\n",
      "Slicing performed in 0.002901792526245117 seconds.\n",
      "Prediction performed in 0.1743767261505127 seconds.\n",
      "Sliced Prediction time is: 177.24 ms\n",
      "*****************************************\n",
      "File Name 0000087_01580_d_0000005\n",
      "Initial Prediction time is: 14.89 ms\n",
      "Object Density: 41\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 252\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  252\n",
      "Final Bounding Box Count (Truncated NMS):  66\n",
      "Slicing performed in 0.0029125213623046875 seconds.\n",
      "Prediction performed in 0.24086999893188477 seconds.\n",
      "Sliced Prediction time is: 243.76 ms\n",
      "*****************************************\n",
      "File Name 0000078_01314_d_0000004\n",
      "Initial Prediction time is: 21.34 ms\n",
      "Object Density: 0\n",
      "Prediction time is: 21.34 ms\n",
      "*****************************************\n",
      "File Name 0000054_00786_d_0000001\n",
      "Initial Prediction time is: 14.35 ms\n",
      "Object Density: 71\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 372\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  372\n",
      "Final Bounding Box Count (Truncated NMS):  94\n",
      "Slicing performed in 0.002454996109008789 seconds.\n",
      "Prediction performed in 0.36621713638305664 seconds.\n",
      "Sliced Prediction time is: 369.23 ms\n",
      "*****************************************\n",
      "File Name 0000192_00522_d_0000213\n",
      "Initial Prediction time is: 15.80 ms\n",
      "Object Density: 25\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 215\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  215\n",
      "Final Bounding Box Count (Truncated NMS):  44\n",
      "Slicing performed in 0.0030524730682373047 seconds.\n",
      "Prediction performed in 0.19258975982666016 seconds.\n",
      "Sliced Prediction time is: 195.12 ms\n",
      "*****************************************\n",
      "File Name 0000078_06777_d_0000020\n",
      "Initial Prediction time is: 21.97 ms\n",
      "Object Density: 3\n",
      "Prediction time is: 21.97 ms\n",
      "Prediction results are successfully exported to sliced_predictions/exp202\n",
      "Prediction Completed Successfully: 15 images\n",
      "Total Prediction time for all images is: 5549.09 ms\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Adaptive-Optimized-NMS (Adaptive-OptNMS-ALL) - min-area-1024\n",
    "source_folder = './test_vis_data/images'\n",
    "json_path = \"./subset_vis_test_data_15.json\"\n",
    "slice_size = 512\n",
    "result_preds_adapt_nms_opt_iou_all = predict_sliced_images(source_folder, json_path, detection_model, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf1c8ee-3718-4db4-9dc4-af6e433987e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.55s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.300\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.472\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.253\n",
      "COCO evaluation results are successfully exported to sliced_predictions/exp202/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD (Adaptive-TruncatedNMS-ALL)\n",
    "!sahi coco evaluate --dataset_json_path './subset_vis_test_data_15.json' --result_json_path './sliced_predictions/exp202/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43bcf972-184a-42ed-a15e-36fbd5036d6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST PROCESSING: TruncatedNMS\n",
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|██████████| 15/15 [00:00<00:00, 296.98it/s]\n",
      "Performing inference on images:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000207_00300_d_0000004\n",
      "Image Size:  (960, 540)\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 265\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:   7%|▋         | 1/15 [00:00<00:04,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  63\n",
      "Prediction time is: 271.98 ms\n",
      "Image Name: 0000074_07850_d_0000015\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 15\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 15 slices.\n",
      "Original Prediction Count 465\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:   7%|▋         | 1/15 [00:01<00:04,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  142\n",
      "Prediction time is: 683.30 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  13%|█▎        | 2/15 [00:01<00:08,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000187_00444_d_0000190\n",
      "Image Size:  (960, 540)\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 217\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  196\n",
      "Final Bounding Box Count (Truncated NMS):  40\n",
      "Prediction time is: 170.49 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  20%|██        | 3/15 [00:01<00:05,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000207_00600_d_0000007\n",
      "Image Size:  (960, 540)\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 419\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  27%|██▋       | 4/15 [00:01<00:04,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  93\n",
      "Prediction time is: 342.43 ms\n",
      "Image Name: 0000087_00299_d_0000002\n",
      "Image Size:  (960, 540)\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 480\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  33%|███▎      | 5/15 [00:02<00:04,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  105\n",
      "Prediction time is: 413.64 ms\n",
      "Image Name: 0000259_00500_d_0000002\n",
      "Image Size:  (1360, 765)\n",
      "Sliced Boxes Count: 8\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 8 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  40%|████      | 6/15 [00:02<00:03,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prediction Count 122\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  109\n",
      "Final Bounding Box Count (Truncated NMS):  44\n",
      "Prediction time is: 180.13 ms\n",
      "Image Name: 0000074_08202_d_0000016\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 15\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 15 slices.\n",
      "Original Prediction Count 437\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  40%|████      | 6/15 [00:03<00:03,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  122\n",
      "Prediction time is: 573.27 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  47%|████▋     | 7/15 [00:03<00:04,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000011_04202_d_0000007\n",
      "Image Size:  (1360, 765)\n",
      "Sliced Boxes Count: 8\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 114\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  87\n",
      "Final Bounding Box Count (Truncated NMS):  30\n",
      "Prediction time is: 163.13 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  53%|█████▎    | 8/15 [00:03<00:03,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000189_00297_d_0000198\n",
      "Image Size:  (960, 540)\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 236\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  210\n",
      "Final Bounding Box Count (Truncated NMS):  44\n",
      "Prediction time is: 186.96 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  60%|██████    | 9/15 [00:04<00:02,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000186_01387_d_0000188\n",
      "Image Size:  (960, 540)\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 207\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  183\n",
      "Final Bounding Box Count (Truncated NMS):  46\n",
      "Prediction time is: 173.91 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  67%|██████▋   | 10/15 [00:04<00:01,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000087_01580_d_0000005\n",
      "Image Size:  (960, 540)\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 305\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  73%|███████▎  | 11/15 [00:04<00:01,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  66\n",
      "Prediction time is: 238.40 ms\n",
      "Image Name: 0000078_01314_d_0000004\n",
      "Image Size:  (1360, 765)\n",
      "Sliced Boxes Count: 8\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 4\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  4\n",
      "Final Bounding Box Count (Truncated NMS):  2\n",
      "Prediction time is: 134.02 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  80%|████████  | 12/15 [00:04<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000054_00786_d_0000001\n",
      "Image Size:  (960, 540)\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 432\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  87%|████████▋ | 13/15 [00:05<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  89\n",
      "Prediction time is: 359.48 ms\n",
      "Image Name: 0000192_00522_d_0000213\n",
      "Image Size:  (960, 540)\n",
      "Sliced Boxes Count: 6\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 245\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  93%|█████████▎| 14/15 [00:05<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  44\n",
      "Prediction time is: 188.36 ms\n",
      "Image Name: 0000078_06777_d_0000020\n",
      "Image Size:  (1360, 765)\n",
      "Sliced Boxes Count: 8\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 13\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  12\n",
      "Final Bounding Box Count (Truncated NMS):  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images: 100%|██████████| 15/15 [00:05<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time is: 135.18 ms\n",
      "Prediction results are successfully exported to runs/predict/exp225\n",
      "Model loaded in 0.051589012145996094 seconds.\n",
      "Slicing performed in 0.014005899429321289 seconds.\n",
      "Prediction performed in 4.214673280715942 seconds.\n",
      "Exporting performed in 0.042687177658081055 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_predict_truncatednms_15_all = predict(source='./test_vis_data',\n",
    "                         dataset_json_path = './subset_vis_test_data_15.json',\n",
    "                         model_type = 'ultralytics',\n",
    "                         model_path = 'models/yolov8/last.pt',\n",
    "                         slice_height = 512,\n",
    "                         slice_width = 512,\n",
    "                         overlap_height_ratio = 0.25,\n",
    "                         overlap_width_ratio = 0.25,\n",
    "                         postprocess_type = \"TruncatedNMS\",\n",
    "                         postprocess_min_area =  16,\n",
    "                         postprocess_conf_threshold = 0.3,                  \n",
    "                         verbose = 2\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f498198-012a-4561-8fa2-74f4a4b66e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.54s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.054\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.053\n",
      "COCO evaluation results are successfully exported to runs/predict/exp225/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD (TruncatedNMS-ALL)\n",
    "!sahi coco evaluate --dataset_json_path './subset_vis_test_data_15.json' --result_json_path './runs/predict/exp225/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "719d5918-fa56-41cb-ae83-087989d6f24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST PROCESSING: TruncatedNMS\n",
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|██████████| 10/10 [00:00<00:00, 182.90it/s]\n",
      "Performing inference on images:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000074_03738_d_0000007\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 548\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  96\n",
      "Prediction time is: 784.66 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  10%|█         | 1/10 [00:01<00:08,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000074_07850_d_0000015\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 1004\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  10%|█         | 1/10 [00:02<00:08,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  154\n",
      "Prediction time is: 1441.15 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  20%|██        | 2/10 [00:02<00:11,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000074_02723_d_0000005\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 638\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  30%|███       | 3/10 [00:03<00:08,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  101\n",
      "Prediction time is: 810.70 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  30%|███       | 3/10 [00:03<00:08,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000074_08202_d_0000016\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 869\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  30%|███       | 3/10 [00:04<00:08,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  133\n",
      "Prediction time is: 1093.96 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  40%|████      | 4/10 [00:05<00:07,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000073_05999_d_0000007\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 677\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  50%|█████     | 5/10 [00:06<00:05,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  113\n",
      "Prediction time is: 859.31 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  50%|█████     | 5/10 [00:06<00:05,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000074_05715_d_0000011\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 699\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  60%|██████    | 6/10 [00:07<00:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  111\n",
      "Prediction time is: 896.19 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  60%|██████    | 6/10 [00:07<00:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000074_07297_d_0000014\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 984\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  60%|██████    | 6/10 [00:08<00:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  148\n",
      "Prediction time is: 1243.01 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  70%|███████   | 7/10 [00:08<00:03,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000074_06746_d_0000013\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 893\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  70%|███████   | 7/10 [00:09<00:03,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  141\n",
      "Prediction time is: 1142.27 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  80%|████████  | 8/10 [00:10<00:02,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000074_01218_d_0000002\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 638\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  90%|█████████ | 9/10 [00:11<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (Truncated NMS):  120\n",
      "Prediction time is: 850.84 ms\n",
      "Image Name: 0000074_08777_d_0000017\n",
      "Image Size:  (1920, 1080)\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  90%|█████████ | 9/10 [00:11<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prediction Count 174\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  131\n",
      "Final Bounding Box Count (Truncated NMS):  48\n",
      "Prediction time is: 497.13 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images: 100%|██████████| 10/10 [00:11<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results are successfully exported to runs/predict/exp227\n",
      "Model loaded in 0.3035259246826172 seconds.\n",
      "Slicing performed in 0.02210831642150879 seconds.\n",
      "Prediction performed in 9.61922287940979 seconds.\n",
      "Exporting performed in 0.07789754867553711 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_predict_truncatednms_10_all = predict(source='./test_visdrone_data',\n",
    "                         dataset_json_path = './subset_visdrone_test_data_10.json',\n",
    "                         model_type = 'ultralytics',\n",
    "                         model_path = 'models/yolov8/last.pt',\n",
    "                         slice_height = 512,\n",
    "                         slice_width = 512,\n",
    "                         overlap_height_ratio = 0.5,\n",
    "                         overlap_width_ratio = 0.5,\n",
    "                         postprocess_type = \"TruncatedNMS\",\n",
    "                         postprocess_min_area =  16,\n",
    "                         postprocess_conf_threshold = 0.3,                  \n",
    "                         verbose = 2\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "201363d7-cbb3-4c94-8e96-9a98ab6efd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.022\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.049\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.145\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.049\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.001\n",
      "COCO evaluation results are successfully exported to runs/predict/exp227/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD (TruncatedNMS-ALL)\n",
    "!sahi coco evaluate --dataset_json_path './subset_visdrone_test_data_10.json' --result_json_path './runs/predict/exp227/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ccea228-01f3-44e3-a29b-6ca2cc1ea715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "File Name 0000074_03738_d_0000007\n",
      "Initial Prediction time is: 41.28 ms\n",
      "Object Density: 52\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 408\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  408\n",
      "Final Bounding Box Count (Truncated NMS):  96\n",
      "Slicing performed in 0.01041102409362793 seconds.\n",
      "Prediction performed in 0.7468652725219727 seconds.\n",
      "Sliced Prediction time is: 755.80 ms\n",
      "*****************************************\n",
      "File Name 0000074_07850_d_0000015\n",
      "Initial Prediction time is: 36.36 ms\n",
      "Object Density: 53\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 826\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  826\n",
      "Final Bounding Box Count (Truncated NMS):  154\n",
      "Slicing performed in 0.009911060333251953 seconds.\n",
      "Prediction performed in 1.4558138847351074 seconds.\n",
      "Sliced Prediction time is: 1464.29 ms\n",
      "*****************************************\n",
      "File Name 0000074_02723_d_0000005\n",
      "Initial Prediction time is: 37.94 ms\n",
      "Object Density: 64\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 484\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  484\n",
      "Final Bounding Box Count (Truncated NMS):  101\n",
      "Slicing performed in 0.010749101638793945 seconds.\n",
      "Prediction performed in 0.8283617496490479 seconds.\n",
      "Sliced Prediction time is: 836.23 ms\n",
      "*****************************************\n",
      "File Name 0000074_08202_d_0000016\n",
      "Initial Prediction time is: 36.65 ms\n",
      "Object Density: 50\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 672\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  672\n",
      "Final Bounding Box Count (Truncated NMS):  133\n",
      "Slicing performed in 0.011149168014526367 seconds.\n",
      "Prediction performed in 1.1120433807373047 seconds.\n",
      "Sliced Prediction time is: 1121.12 ms\n",
      "*****************************************\n",
      "File Name 0000073_05999_d_0000007\n",
      "Initial Prediction time is: 37.37 ms\n",
      "Object Density: 52\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 500\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  500\n",
      "Final Bounding Box Count (Truncated NMS):  113\n",
      "Slicing performed in 0.011342763900756836 seconds.\n",
      "Prediction performed in 0.884904146194458 seconds.\n",
      "Sliced Prediction time is: 893.75 ms\n",
      "*****************************************\n",
      "File Name 0000074_05715_d_0000011\n",
      "Initial Prediction time is: 37.45 ms\n",
      "Object Density: 32\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "Sliced Boxes Count: 15\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 15 slices.\n",
      "Original Prediction Count 294\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  294\n",
      "Final Bounding Box Count (Truncated NMS):  113\n",
      "Slicing performed in 0.011444807052612305 seconds.\n",
      "Prediction performed in 0.5276761054992676 seconds.\n",
      "Sliced Prediction time is: 536.83 ms\n",
      "*****************************************\n",
      "File Name 0000074_07297_d_0000014\n",
      "Initial Prediction time is: 35.47 ms\n",
      "Object Density: 39\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "Sliced Boxes Count: 15\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 15 slices.\n",
      "Original Prediction Count 333\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  333\n",
      "Final Bounding Box Count (Truncated NMS):  138\n",
      "Slicing performed in 0.00983881950378418 seconds.\n",
      "Prediction performed in 0.6198234558105469 seconds.\n",
      "Sliced Prediction time is: 628.70 ms\n",
      "*****************************************\n",
      "File Name 0000074_06746_d_0000013\n",
      "Initial Prediction time is: 38.32 ms\n",
      "Object Density: 29\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "Sliced Boxes Count: 15\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 15 slices.\n",
      "Original Prediction Count 397\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  397\n",
      "Final Bounding Box Count (Truncated NMS):  134\n",
      "Slicing performed in 0.010864019393920898 seconds.\n",
      "Prediction performed in 0.6642014980316162 seconds.\n",
      "Sliced Prediction time is: 673.11 ms\n",
      "*****************************************\n",
      "File Name 0000074_01218_d_0000002\n",
      "Initial Prediction time is: 36.60 ms\n",
      "Object Density: 67\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "Sliced Boxes Count: 28\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 28 slices.\n",
      "Original Prediction Count 483\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  483\n",
      "Final Bounding Box Count (Truncated NMS):  120\n",
      "Slicing performed in 0.010582685470581055 seconds.\n",
      "Prediction performed in 0.8717384338378906 seconds.\n",
      "Sliced Prediction time is: 879.77 ms\n",
      "*****************************************\n",
      "File Name 0000074_08777_d_0000017\n",
      "Initial Prediction time is: 35.84 ms\n",
      "Object Density: 29\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "Sliced Boxes Count: 15\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 15 slices.\n",
      "Original Prediction Count 80\n",
      "Confidence Scores:  0.3\n",
      "Min area Threshold:  16\n",
      "Adaptive Filtered Prediction:  80\n",
      "Final Bounding Box Count (Truncated NMS):  42\n",
      "Slicing performed in 0.010176897048950195 seconds.\n",
      "Prediction performed in 0.2999582290649414 seconds.\n",
      "Sliced Prediction time is: 308.25 ms\n",
      "Prediction results are successfully exported to sliced_predictions/exp203\n",
      "Prediction Completed Successfully: 10 images\n",
      "Total Prediction time for all images is: 8471.13 ms\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Adaptive-Optimized-NMS (TruncatedNMS-ALL) - min-area-16\n",
    "source_folder = './test_visdrone_data/images'\n",
    "json_path = \"./subset_visdrone_test_data_10.json\"\n",
    "slice_size = 512\n",
    "result_preds_adapt_nms_opt_iou_all = predict_sliced_images(source_folder, json_path, detection_model, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dbf40d1-4170-4714-b8cd-ebdff9fb1f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.86s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = 0.672\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.557\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.571\n",
      "COCO evaluation results are successfully exported to sliced_predictions/exp203/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD\n",
    "!sahi coco evaluate --dataset_json_path './subset_visdrone_test_data_10.json' --result_json_path './sliced_predictions/exp203/result.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a95d3a-e4cf-43b4-90cd-353f675853dc",
   "metadata": {},
   "source": [
    "#### **Take 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dfb97c8-b0fc-4e12-a4d6-7378fbece8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "File Name 9999952_00000_d_0000029\n",
      "Intial Prediction time is: 22.68 ms\n",
      "Object Density: 9\n",
      "Prediction time is: 22.68 ms\n",
      "Prediction results are successfully exported to sliced_predictions/exp145\n",
      "Prediction Completed Sucessfully: 1 images\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Adaptive-Optimized-NMS\n",
    "source_folder = './single_test/images'\n",
    "json_path = \"./subset_vis_test_data_428.json\"\n",
    "slice_size = 512\n",
    "result_preds_adapt_opt_nms_iou_size = predict_sliced_images(source_folder, json_path, detection_model, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bd454fa-c111-4313-b29d-c73a4794804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.034\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.500\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.283\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      "COCO evaluation results are successfully exported to sliced_predictions/exp145/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD\n",
    "!sahi coco evaluate --dataset_json_path './subset_vis_test_data_428.json' --result_json_path './sliced_predictions/exp145/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "580a8c98-67cc-4f46-967d-103bed67e530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "File Name 9999938_00000_d_0000207\n",
      "Intial Prediction time is: 29.11 ms\n",
      "Object Density: 24\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.15\n",
      "Overlap Height Ratio:  0.15\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 341\n",
      "Adaptive Prediction Count 341\n",
      "Total Valid prediction:  187\n",
      "Slicing performed in 0.008407115936279297 seconds.\n",
      "Prediction performed in 0.7021129131317139 seconds.\n",
      "Sliced Prediction time is: 708.08 ms\n",
      "*****************************************\n",
      "File Name 0000006_05208_d_0000014\n",
      "Intial Prediction time is: 23.04 ms\n",
      "Object Density: 17\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.15\n",
      "Overlap Height Ratio:  0.15\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 44\n",
      "Adaptive Prediction Count 44\n",
      "Total Valid prediction:  9\n",
      "Slicing performed in 0.0057964324951171875 seconds.\n",
      "Prediction performed in 0.12571096420288086 seconds.\n",
      "Sliced Prediction time is: 130.57 ms\n",
      "*****************************************\n",
      "File Name 0000370_02000_d_0000254\n",
      "Intial Prediction time is: 21.57 ms\n",
      "Object Density: 2\n",
      "Prediction time is: 21.57 ms\n",
      "*****************************************\n",
      "File Name 0000006_06773_d_0000018\n",
      "Intial Prediction time is: 23.67 ms\n",
      "Object Density: 37\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 110\n",
      "Adaptive Prediction Count 110\n",
      "Total Valid prediction:  34\n",
      "Slicing performed in 0.006308794021606445 seconds.\n",
      "Prediction performed in 0.18512320518493652 seconds.\n",
      "Sliced Prediction time is: 191.00 ms\n",
      "*****************************************\n",
      "File Name 0000006_05999_d_0000017\n",
      "Intial Prediction time is: 23.26 ms\n",
      "Object Density: 59\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 10 slices.\n",
      "Original Prediction Count 212\n",
      "Adaptive Prediction Count 212\n",
      "Total Valid prediction:  61\n",
      "Slicing performed in 0.006152153015136719 seconds.\n",
      "Prediction performed in 0.29753541946411133 seconds.\n",
      "Sliced Prediction time is: 303.03 ms\n",
      "Prediction results are successfully exported to sliced_predictions/exp146\n",
      "Prediction Completed Sucessfully: 5 images\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Adaptive-Optimized-NMS\n",
    "source_folder = './test_data/images'\n",
    "json_path = \"./subset_visdrone_test_data.json\"\n",
    "slice_size = 512\n",
    "result_preds_adapt_opt_nms_iou_size = predict_sliced_images(source_folder, json_path, detection_model, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a9f350f-df06-41e1-9fb7-8863d24dfd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.40s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.355\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.283\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.668\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = 0.297\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.504\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.237\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.591\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.212\n",
      "COCO evaluation results are successfully exported to sliced_predictions/exp146/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD\n",
    "!sahi coco evaluate --dataset_json_path './subset_visdrone_test_data.json' --result_json_path './sliced_predictions/exp146/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8287e12-8fd7-4dde-8ecc-76e3ce5b8657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "File Name 9999938_00000_d_0000207\n",
      "Intial Prediction time is: 29.81 ms\n",
      "Object Density: 24\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.15\n",
      "Overlap Height Ratio:  0.15\n",
      "POST PROCESS:  OptNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 341\n",
      "Filtered Prediction:  198\n",
      "Final Bounding Box Count: 108\n",
      "Filtered Prediction:  81\n",
      "Final Bounding Box Count: 59\n",
      "Filtered Prediction:  17\n",
      "Final Bounding Box Count: 10\n",
      "Filtered Prediction:  3\n",
      "Final Bounding Box Count: 2\n",
      "Filtered Prediction:  1\n",
      "Final Bounding Box Count: 1\n",
      "Filtered Prediction:  21\n",
      "Final Bounding Box Count: 9\n",
      "Filtered Prediction:  20\n",
      "Final Bounding Box Count: 11\n",
      "Slicing performed in 0.007295370101928711 seconds.\n",
      "Prediction performed in 0.18048357963562012 seconds.\n",
      "Sliced Prediction time is: 186.29 ms\n",
      "*****************************************\n",
      "File Name 0000006_05208_d_0000014\n",
      "Intial Prediction time is: 23.24 ms\n",
      "Object Density: 17\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.15\n",
      "Overlap Height Ratio:  0.15\n",
      "POST PROCESS:  OptNMS\n",
      "Performing prediction on 6 slices.\n",
      "Original Prediction Count 44\n",
      "Filtered Prediction:  1\n",
      "Final Bounding Box Count: 1\n",
      "Filtered Prediction:  3\n",
      "Final Bounding Box Count: 2\n",
      "Filtered Prediction:  40\n",
      "Final Bounding Box Count: 8\n",
      "Slicing performed in 0.00565028190612793 seconds.\n",
      "Prediction performed in 0.12176394462585449 seconds.\n",
      "Sliced Prediction time is: 126.74 ms\n",
      "*****************************************\n",
      "File Name 0000370_02000_d_0000254\n",
      "Intial Prediction time is: 21.64 ms\n",
      "Object Density: 2\n",
      "Prediction time is: 21.64 ms\n",
      "*****************************************\n",
      "File Name 0000006_06773_d_0000018\n",
      "Intial Prediction time is: 23.72 ms\n",
      "Object Density: 37\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "POST PROCESS:  OptNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 110\n",
      "Filtered Prediction:  41\n",
      "Final Bounding Box Count: 20\n",
      "Filtered Prediction:  8\n",
      "Final Bounding Box Count: 4\n",
      "Filtered Prediction:  54\n",
      "Final Bounding Box Count: 11\n",
      "Filtered Prediction:  5\n",
      "Final Bounding Box Count: 3\n",
      "Filtered Prediction:  2\n",
      "Final Bounding Box Count: 2\n",
      "Slicing performed in 0.006227254867553711 seconds.\n",
      "Prediction performed in 0.15802621841430664 seconds.\n",
      "Sliced Prediction time is: 163.85 ms\n",
      "*****************************************\n",
      "File Name 0000006_05999_d_0000017\n",
      "Intial Prediction time is: 24.05 ms\n",
      "Object Density: 59\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.5\n",
      "Overlap Height Ratio:  0.5\n",
      "POST PROCESS:  OptNMS\n",
      "Performing prediction on 10 slices.\n",
      "Original Prediction Count 212\n",
      "Filtered Prediction:  51\n",
      "Final Bounding Box Count: 21\n",
      "Filtered Prediction:  12\n",
      "Final Bounding Box Count: 9\n",
      "Filtered Prediction:  108\n",
      "Final Bounding Box Count: 36\n",
      "Filtered Prediction:  39\n",
      "Final Bounding Box Count: 18\n",
      "Filtered Prediction:  2\n",
      "Final Bounding Box Count: 1\n",
      "Slicing performed in 0.005928516387939453 seconds.\n",
      "Prediction performed in 0.1967790126800537 seconds.\n",
      "Sliced Prediction time is: 201.54 ms\n",
      "Prediction results are successfully exported to sliced_predictions/exp147\n",
      "Prediction Completed Sucessfully: 5 images\n",
      "Total Prediction time is: 225.59 ms\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Adaptive-Optimized-NMS (OptNMS)\n",
    "source_folder = './test_data/images'\n",
    "json_path = \"./subset_visdrone_test_data.json\"\n",
    "slice_size = 512\n",
    "result_preds_adapt_opt_nms_iou_size = predict_sliced_images(source_folder, json_path, detection_model, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ff2b598-7e2d-4133-8c8d-927116fdcca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.361\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.291\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.654\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = 0.350\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.488\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.602\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.259\n",
      "COCO evaluation results are successfully exported to sliced_predictions/exp147/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD\n",
    "!sahi coco evaluate --dataset_json_path './subset_visdrone_test_data.json' --result_json_path './sliced_predictions/exp147/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a29df3d1-961f-4b2c-b1eb-7cdcdde2535e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST PROCESSING: NMS\n",
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|██████████| 5/5 [00:00<00:00, 160.87it/s]\n",
      "Performing inference on images:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 9999938_00000_d_0000207\n",
      "Image Size:  (1400, 788)\n",
      "POST PROCESS:  NMS\n",
      "Performing prediction on 15 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  20%|██        | 1/5 [00:00<00:02,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Valid prediction:  153\n",
      "Total Valid prediction:  1\n",
      "Total Valid prediction:  62\n",
      "Total Valid prediction:  15\n",
      "Total Valid prediction:  3\n",
      "Total Valid prediction:  1\n",
      "Total Valid prediction:  9\n",
      "Total Valid prediction:  22\n",
      "Prediction time is: 352.77 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  20%|██        | 1/5 [00:00<00:02,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000006_05208_d_0000014\n",
      "Image Size:  (1360, 765)\n",
      "POST PROCESS:  NMS\n",
      "Performing prediction on 10 slices.\n",
      "Total Valid prediction:  1\n",
      "Total Valid prediction:  2\n",
      "Total Valid prediction:  8\n",
      "Prediction time is: 171.05 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  40%|████      | 2/5 [00:00<00:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000370_02000_d_0000254\n",
      "Image Size:  (1360, 765)\n",
      "POST PROCESS:  NMS\n",
      "Performing prediction on 10 slices.\n",
      "Total Valid prediction:  4\n",
      "Total Valid prediction:  1\n",
      "Prediction time is: 165.21 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  60%|██████    | 3/5 [00:01<00:00,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000006_06773_d_0000018\n",
      "Image Size:  (1360, 765)\n",
      "POST PROCESS:  NMS\n",
      "Performing prediction on 10 slices.\n",
      "Total Valid prediction:  1\n",
      "Total Valid prediction:  21\n",
      "Total Valid prediction:  8\n",
      "Total Valid prediction:  13\n",
      "Total Valid prediction:  3\n",
      "Total Valid prediction:  2\n",
      "Prediction time is: 176.44 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  80%|████████  | 4/5 [00:01<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000006_05999_d_0000017\n",
      "Image Size:  (1360, 765)\n",
      "POST PROCESS:  NMS\n",
      "Performing prediction on 10 slices.\n",
      "Total Valid prediction:  22\n",
      "Total Valid prediction:  9\n",
      "Total Valid prediction:  40\n",
      "Total Valid prediction:  22\n",
      "Total Valid prediction:  1\n",
      "Prediction time is: 183.31 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images: 100%|██████████| 5/5 [00:01<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results are successfully exported to runs/predict/exp177\n",
      "Model loaded in 0.0471343994140625 seconds.\n",
      "Slicing performed in 0.0055065155029296875 seconds.\n",
      "Prediction performed in 1.0487713813781738 seconds.\n",
      "Exporting performed in 0.04857182502746582 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_predict_nms_2 = predict(source='./test_data',\n",
    "                         dataset_json_path = './subset_visdrone_test_data.json',\n",
    "                         model_type = 'ultralytics',\n",
    "                         model_path = 'models/yolov8/last.pt',\n",
    "                         slice_height = 512,\n",
    "                         slice_width = 512,\n",
    "                         overlap_height_ratio = 0.5,\n",
    "                         overlap_width_ratio = 0.5,\n",
    "                         postprocess_type = \"NMS\",\n",
    "                         verbose = 2\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84ae38ac-1591-4524-85f4-43d84cf03cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.57s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.368\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.701\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = 0.360\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.515\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.639\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = 0.241\n",
      "COCO evaluation results are successfully exported to runs/predict/exp177/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD\n",
    "!sahi coco evaluate --dataset_json_path './subset_visdrone_test_data.json' --result_json_path './runs/predict/exp177/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c90db80e-765c-436b-895c-6fa8d87db393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST PROCESSING: NMS\n",
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|██████████| 1/1 [00:00<00:00, 526.06it/s]\n",
      "Performing inference on images:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 9999952_00000_d_0000029\n",
      "Image Size:  (1400, 788)\n",
      "POST PROCESS:  NMS\n",
      "Performing prediction on 15 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Valid prediction:  17\n",
      "Total Valid prediction:  1\n",
      "Prediction time is: 327.30 ms\n",
      "Prediction results are successfully exported to runs/predict/exp175\n",
      "Model loaded in 0.07476592063903809 seconds.\n",
      "Slicing performed in 0.0011415481567382812 seconds.\n",
      "Prediction performed in 0.3273036479949951 seconds.\n",
      "Exporting performed in 0.04234790802001953 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_predict_nms_1 = predict(source='./single_test',\n",
    "                         dataset_json_path = './subset_vis_test_data_428.json',\n",
    "                         model_type = 'ultralytics',\n",
    "                         model_path = 'models/yolov8/last.pt',\n",
    "                         slice_height = 512,\n",
    "                         slice_width = 512,\n",
    "                         overlap_height_ratio = 0.5,\n",
    "                         overlap_width_ratio = 0.5,\n",
    "                         postprocess_type = \"NMS\",\n",
    "                         verbose = 2\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b250192-542c-44f0-ac14-4d95482916c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.458\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.127\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      "COCO evaluation results are successfully exported to runs/predict/exp175/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD\n",
    "!sahi coco evaluate --dataset_json_path './subset_vis_test_data_428.json' --result_json_path './runs/predict/exp175/result.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05a68f-278e-456e-a03d-ebd681318024",
   "metadata": {},
   "source": [
    "##### **Truncated NMS test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06b199ce-b7a8-4fc2-a2a7-d93b79ef8408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "File Name 0000011_05068_d_0000008\n",
      "Intial Prediction time is: 23.70 ms\n",
      "Object Density: 33\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 93\n",
      "Adaptive Filtered Prediction:  93\n",
      "Final Bounding Box Count (Truncated NMS):  47\n",
      "Slicing performed in 0.00583648681640625 seconds.\n",
      "Prediction performed in 0.1876201629638672 seconds.\n",
      "Sliced Prediction time is: 193.40 ms\n",
      "Prediction results are successfully exported to sliced_predictions/exp152\n",
      "Prediction Completed Sucessfully: 1 images\n",
      "Total Prediction time is: 217.10 ms\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Adaptive-Optimized-NMS (Adaptive-TruncatedNMS)\n",
    "source_folder = './single_test/images'\n",
    "json_path = \"./subset_vis_test_data_1162.json\"\n",
    "slice_size = 512\n",
    "result_preds_adapt_opt_nms_iou_size = predict_sliced_images(source_folder, json_path, detection_model, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93c4c669-d000-4bc5-a053-4c4f9f11d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      "COCO evaluation results are successfully exported to sliced_predictions/exp152/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD (Adaptive-TruncatedNMS)\n",
    "!sahi coco evaluate --dataset_json_path './subset_vis_test_data_1162.json' --result_json_path './sliced_predictions/exp152/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc52da0a-b6e3-4836-936c-b0fed368a5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "File Name 0000011_05068_d_0000008\n",
      "Intial Prediction time is: 26.26 ms\n",
      "Object Density: 33\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "POST PROCESS:  OptNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 93\n",
      "Filtered Prediction:  63\n",
      "Final Bounding Box Count: 31\n",
      "Filtered Prediction:  8\n",
      "Final Bounding Box Count: 6\n",
      "Filtered Prediction:  3\n",
      "Final Bounding Box Count: 2\n",
      "Filtered Prediction:  1\n",
      "Final Bounding Box Count: 1\n",
      "Filtered Prediction:  11\n",
      "Final Bounding Box Count: 6\n",
      "Filtered Prediction:  1\n",
      "Final Bounding Box Count: 1\n",
      "Filtered Prediction:  6\n",
      "Final Bounding Box Count: 6\n",
      "Slicing performed in 0.007169246673583984 seconds.\n",
      "Prediction performed in 0.16434741020202637 seconds.\n",
      "Sliced Prediction time is: 169.24 ms\n",
      "Prediction results are successfully exported to sliced_predictions/exp148\n",
      "Prediction Completed Sucessfully: 1 images\n",
      "Total Prediction time is: 195.50 ms\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Adaptive-Optimized-NMS (OptNMS)\n",
    "source_folder = './single_test/images'\n",
    "json_path = \"./subset_vis_test_data_1162.json\"\n",
    "slice_size = 512\n",
    "result_preds_adapt_opt_nms_iou_size = predict_sliced_images(source_folder, json_path, detection_model, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e78085e6-6d3d-4d20-88bc-d5b1543fd587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      "COCO evaluation results are successfully exported to sliced_predictions/exp148/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD (OptNMS)\n",
    "!sahi coco evaluate --dataset_json_path './subset_vis_test_data_1162.json' --result_json_path './sliced_predictions/exp148/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6e4d7c3-a5e9-476b-9c20-3bdb8ae21724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "File Name 0000011_05068_d_0000008\n",
      "Intial Prediction time is: 28.54 ms\n",
      "Object Density: 33\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "POST PROCESS:  TruncatedNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 93\n",
      "Adaptive Prediction Count 93\n",
      "Total Valid prediction:  46\n",
      "Slicing performed in 0.005643367767333984 seconds.\n",
      "Prediction performed in 0.1970047950744629 seconds.\n",
      "Sliced Prediction time is: 202.37 ms\n",
      "Prediction results are successfully exported to sliced_predictions/exp149\n",
      "Prediction Completed Sucessfully: 1 images\n",
      "Total Prediction time is: 230.91 ms\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Adaptive-Optimized-NMS (TruncatedNMS)\n",
    "source_folder = './single_test/images'\n",
    "json_path = \"./subset_vis_test_data_1162.json\"\n",
    "slice_size = 512\n",
    "result_preds_adapt_opt_nms_iou_size = predict_sliced_images(source_folder, json_path, detection_model, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d0a06bb-22a5-4a4e-9bab-2acd911c8f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      "COCO evaluation results are successfully exported to sliced_predictions/exp149/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD (TruncatedNMS)\n",
    "!sahi coco evaluate --dataset_json_path './subset_vis_test_data_1162.json' --result_json_path './sliced_predictions/exp149/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2e471f8-6a7e-4639-9dbb-7fa70f2015d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST PROCESSING: NMS\n",
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|██████████| 1/1 [00:00<00:00, 450.23it/s]\n",
      "Performing inference on images:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000011_05068_d_0000008\n",
      "Image Size:  (1360, 765)\n",
      "POST PROCESS:  NMS\n",
      "Performing prediction on 10 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Valid prediction:  34\n",
      "Total Valid prediction:  9\n",
      "Total Valid prediction:  3\n",
      "Total Valid prediction:  3\n",
      "Total Valid prediction:  7\n",
      "Total Valid prediction:  2\n",
      "Total Valid prediction:  10\n",
      "Prediction time is: 241.23 ms\n",
      "Prediction results are successfully exported to runs/predict/exp178\n",
      "Model loaded in 0.036215782165527344 seconds.\n",
      "Slicing performed in 0.0012192726135253906 seconds.\n",
      "Prediction performed in 0.24123263359069824 seconds.\n",
      "Exporting performed in 0.04652714729309082 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_predict_nms_2 = predict(source='./single_test',\n",
    "                         dataset_json_path = './subset_vis_test_data_1162.json',\n",
    "                         model_type = 'ultralytics',\n",
    "                         model_path = 'models/yolov8/last.pt',\n",
    "                         slice_height = 512,\n",
    "                         slice_width = 512,\n",
    "                         overlap_height_ratio = 0.5,\n",
    "                         overlap_width_ratio = 0.5,\n",
    "                         postprocess_type = \"NMS\",\n",
    "                         verbose = 2\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2aa32891-e578-4809-aaa1-807d4919e93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      "COCO evaluation results are successfully exported to runs/predict/exp178/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD (NMS)\n",
    "!sahi coco evaluate --dataset_json_path './subset_vis_test_data_1162.json' --result_json_path './runs/predict/exp178/result.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc49bbe-3ab8-4f98-807b-39c4f752604e",
   "metadata": {},
   "source": [
    "**Take 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cb1497e-7620-42a0-af00-ddc3eea17e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "File Name 0000011_05068_d_0000008\n",
      "Intial Prediction time is: 25.83 ms\n",
      "Object Density: 33\n",
      "********* Slice Parameters ***********\n",
      "Slice Width:  512\n",
      "Slice Height:  512\n",
      "Overlap Width Ratio:  0.25\n",
      "Overlap Height Ratio:  0.25\n",
      "POST PROCESS:  OptNMS\n",
      "Performing prediction on 8 slices.\n",
      "Original Prediction Count 93\n",
      "Adaptive Filtered Prediction:  63\n",
      "Final Bounding Box Count (OptNMS): 31\n",
      "Adaptive Filtered Prediction:  8\n",
      "Final Bounding Box Count (OptNMS): 6\n",
      "Adaptive Filtered Prediction:  3\n",
      "Final Bounding Box Count (OptNMS): 2\n",
      "Adaptive Filtered Prediction:  1\n",
      "Final Bounding Box Count (OptNMS): 1\n",
      "Adaptive Filtered Prediction:  11\n",
      "Final Bounding Box Count (OptNMS): 6\n",
      "Adaptive Filtered Prediction:  1\n",
      "Final Bounding Box Count (OptNMS): 1\n",
      "Adaptive Filtered Prediction:  6\n",
      "Final Bounding Box Count (OptNMS): 6\n",
      "Slicing performed in 0.005602598190307617 seconds.\n",
      "Prediction performed in 0.1577591896057129 seconds.\n",
      "Sliced Prediction time is: 162.79 ms\n",
      "Prediction results are successfully exported to sliced_predictions/exp154\n",
      "Prediction Completed Sucessfully: 1 images\n",
      "Total Prediction time is: 188.61 ms\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Adaptive-Optimized-NMS (OptNMS)\n",
    "source_folder = './single_test/images'\n",
    "json_path = \"./subset_vis_test_data_1162.json\"\n",
    "slice_size = 512\n",
    "result_preds_adapt_opt_nms_iou_size_2 = predict_sliced_images(source_folder, json_path, detection_model, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a19da0bd-c91f-4c22-8bcd-a92fcc89120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      "COCO evaluation results are successfully exported to sliced_predictions/exp154/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD (OptNMS)\n",
    "!sahi coco evaluate --dataset_json_path './subset_vis_test_data_1162.json' --result_json_path './sliced_predictions/exp154/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "368862d7-ab98-43dd-8165-684637446600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST PROCESSING: NMS\n",
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|██████████| 1/1 [00:00<00:00, 460.10it/s]\n",
      "Performing inference on images:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000011_05068_d_0000008\n",
      "Image Size:  (1360, 765)\n",
      "POST PROCESS:  NMS\n",
      "Performing prediction on 10 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bounding Box Count (NMS):  34\n",
      "Final Bounding Box Count (NMS):  9\n",
      "Final Bounding Box Count (NMS):  3\n",
      "Final Bounding Box Count (NMS):  3\n",
      "Final Bounding Box Count (NMS):  7\n",
      "Final Bounding Box Count (NMS):  2\n",
      "Final Bounding Box Count (NMS):  10\n",
      "Prediction time is: 236.71 ms\n",
      "Prediction results are successfully exported to runs/predict/exp179\n",
      "Model loaded in 0.05026555061340332 seconds.\n",
      "Slicing performed in 0.0010750293731689453 seconds.\n",
      "Prediction performed in 0.2367095947265625 seconds.\n",
      "Exporting performed in 0.04619407653808594 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_predict_nms_3 = predict(source='./single_test',\n",
    "                         dataset_json_path = './subset_vis_test_data_1162.json',\n",
    "                         model_type = 'ultralytics',\n",
    "                         model_path = 'models/yolov8/last.pt',\n",
    "                         slice_height = 512,\n",
    "                         slice_width = 512,\n",
    "                         overlap_height_ratio = 0.5,\n",
    "                         overlap_width_ratio = 0.5,\n",
    "                         postprocess_type = \"NMS\",\n",
    "                         verbose = 2\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60a1ebae-3b44-44e7-95af-0d4298271df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      "COCO evaluation results are successfully exported to runs/predict/exp179/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD (NMS)\n",
    "!sahi coco evaluate --dataset_json_path './subset_vis_test_data_1162.json' --result_json_path './runs/predict/exp179/result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fd2c939-1fec-4f04-94c5-e68314b0236f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 32\u001b[0m\n\u001b[1;32m     16\u001b[0m visual_export_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m result \u001b[38;5;241m=\u001b[39m visualize_object_predictions(\n\u001b[1;32m     19\u001b[0m     np\u001b[38;5;241m.\u001b[39mascontiguousarray(image_as_pil),\n\u001b[1;32m     20\u001b[0m     object_prediction_list\u001b[38;5;241m=\u001b[39mobject_prediction_gt_list, \u001b[38;5;66;03m#result2.object_prediction_list,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     export_format\u001b[38;5;241m=\u001b[39m visual_export_format,\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/drive/MyDrive/sahi/runs/predict/exp_test/result_gt.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sahi.utils.cv import read_image_as_pil, visualize_object_predictions\n",
    "# export visualizations with ground truths\n",
    "output_dir = './runs/predict/exp_test'\n",
    "image = './single_test/images/0000011_05068_d_0000008.jpg'\n",
    "image_as_pil = read_image_as_pil(image)\n",
    "color = (0, 255, 0)  # original annotations in green\n",
    "visual_bbox_thickness = 2\n",
    "visual_text_size = 12\n",
    "visual_text_thickness = 10\n",
    "visual_hide_labels = 1\n",
    "visual_hide_conf = 1\n",
    "file_name = 'result_gt'\n",
    "filename_prediction = 'prediction_visual_with_gt'\n",
    "visual_export_format = 'png'\n",
    "\n",
    "result = visualize_object_predictions(\n",
    "    np.ascontiguousarray(image_as_pil),\n",
    "    object_prediction_list=object_prediction_gt_list, #result2.object_prediction_list,\n",
    "    rect_th=visual_bbox_thickness,\n",
    "    text_size=visual_text_size,\n",
    "    text_th=visual_text_thickness,\n",
    "    color=color,\n",
    "    hide_labels=visual_hide_labels,\n",
    "    hide_conf=visual_hide_conf,\n",
    "    output_dir=output_dir,\n",
    "    file_name=file_name,\n",
    "    export_format= visual_export_format,\n",
    ")\n",
    "\n",
    "Image(f'/content/drive/MyDrive/sahi/runs/predict/exp_test/result_gt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d107787e-2178-48e7-911d-f99b94f952a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000011_05068_d_0000008.jpg\n"
     ]
    }
   ],
   "source": [
    "ls ./single_test/images/0000011_05068_d_0000008.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a14a3a-2c54-4316-b980-774ccf3f6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sahi.utils.cv import read_image_as_pil, visualize_object_predictions\n",
    "from IPython.display import Image\n",
    "\n",
    "# export visualizations with ground truths\n",
    "output_dir = 'runs/predict/exp_test'\n",
    "image = 'test_data/0000006_06773_d_0000018.jpg'\n",
    "image_as_pil = read_image_as_pil(image)\n",
    "color = (0, 255, 0)  # original annotations in green\n",
    "visual_bbox_gt_thickness = 3\n",
    "visual_bbox_thickness = 2\n",
    "visual_text_size = 12\n",
    "visual_text_thickness = 10\n",
    "visual_hide_labels = 1\n",
    "visual_hide_conf = 1\n",
    "file_name = 'result_gt'\n",
    "filename_prediction = 'prediction_visual_with_gt'\n",
    "visual_export_format = 'png'\n",
    "\n",
    "result = visualize_object_predictions(\n",
    "    np.ascontiguousarray(image_as_pil),\n",
    "    object_prediction_list= result2.object_prediction_list,\n",
    "    rect_th=visual_bbox_gt_thickness,\n",
    "    text_size=visual_text_size,\n",
    "    text_th=visual_text_thickness,\n",
    "    color=color,\n",
    "    hide_labels=visual_hide_labels,\n",
    "    hide_conf=visual_hide_conf,\n",
    "    output_dir=None,\n",
    "    file_name=None,\n",
    "    export_format= visual_export_format,\n",
    ")\n",
    "color = (255, 0, 0)  # model predictions in red\n",
    "_ = visualize_object_predictions(\n",
    "    result[\"image\"],\n",
    "    object_prediction_list=result_sahi.object_prediction_list,\n",
    "    rect_th=visual_bbox_thickness,\n",
    "    text_size=visual_text_size,\n",
    "    text_th=visual_text_thickness,\n",
    "    color=color,\n",
    "    hide_labels=visual_hide_labels,\n",
    "    hide_conf=visual_hide_conf,\n",
    "    output_dir=output_dir,\n",
    "    file_name=filename_prediction,\n",
    "    export_format=visual_export_format,\n",
    ")\n",
    "\n",
    "Image(f'runs/predict/exp_test/prediction_visual_with_gt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef9c35eb-7fac-44f8-85b6-2d7cdceb44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the JSON annotation file\n",
    "json_path = \"../data/VisDrone2COCO/COCO/annotations/visdrone_coco_test.json\"\n",
    "with open(json_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "image_id = 1162 # Change this to your target image_id\n",
    "\n",
    "def get_annotations(image_id):\n",
    "    return [anno for anno in data[\"annotations\"] if anno[\"image_id\"] == image_id]\n",
    "\n",
    "annotations = get_annotations(image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86ef42ab-ec4d-4e67-8d59-1d7e06396339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST PROCESSING: OptNMS\n",
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|██████████| 1/1 [00:00<00:00, 495.20it/s]\n",
      "Performing inference on images:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 0000011_05068_d_0000008\n",
      "Image Size:  (1360, 765)\n",
      "POST PROCESS:  OptNMS\n",
      "Performing prediction on 10 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prediction Count 148\n",
      "Adaptive Filtered Prediction:  68\n",
      "Final Bounding Box Count (OptNMS): 32\n",
      "Adaptive Filtered Prediction:  7\n",
      "Final Bounding Box Count (OptNMS): 5\n",
      "Adaptive Filtered Prediction:  5\n",
      "Final Bounding Box Count (OptNMS): 3\n",
      "Adaptive Filtered Prediction:  2\n",
      "Final Bounding Box Count (OptNMS): 2\n",
      "Adaptive Filtered Prediction:  13\n",
      "Final Bounding Box Count (OptNMS): 6\n",
      "Adaptive Filtered Prediction:  2\n",
      "Final Bounding Box Count (OptNMS): 1\n",
      "Adaptive Filtered Prediction:  7\n",
      "Final Bounding Box Count (OptNMS): 7\n",
      "Prediction time is: 232.94 ms\n",
      "Prediction results are successfully exported to runs/predict/exp180\n",
      "Model loaded in 0.30643177032470703 seconds.\n",
      "Slicing performed in 0.0011594295501708984 seconds.\n",
      "Prediction performed in 0.23293519020080566 seconds.\n",
      "Exporting performed in 0.04785895347595215 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_predict = predict(source='./single_test',\n",
    "                         dataset_json_path = './subset_vis_test_data_1162.json',\n",
    "                         model_type = 'ultralytics',\n",
    "                         model_path = 'models/yolov8/last.pt',\n",
    "                         slice_height = 512,\n",
    "                         slice_width = 512,\n",
    "                         overlap_height_ratio = 0.5,\n",
    "                         overlap_width_ratio = 0.5,\n",
    "                         postprocess_type = \"OptNMS\",\n",
    "                         verbose = 2,\n",
    "                         batch_size = 4\n",
    "                         #model_config_path = config.yaml\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d3256fe-9663-425e-a321-4b27db7f7270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=500 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=500 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=500 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=500 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=500 ] = 0.483\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=500 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=500 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=500 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=500 ] = -1.000\n",
      "COCO evaluation results are successfully exported to runs/predict/exp180/eval.json\n"
     ]
    }
   ],
   "source": [
    "#USING Adaptive-Optimized-NMS-IoU METHOD (NMS)\n",
    "!sahi coco evaluate --dataset_json_path './subset_vis_test_data_1162.json' --result_json_path './runs/predict/exp180/result.json'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch11.8]",
   "language": "python",
   "name": "conda-env-torch11.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
